{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fidanfatih/NLP_Projects/blob/main/Word_Embedding_(word2vec%2C_Glove).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wseBFlNg4dVP"
      },
      "source": [
        "# **NLP Word Embedding (word2vec, Glove)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfCeXHBj5juJ",
        "outputId": "e07bee6b-7bf3-4ed0-ca73-e548772c7a64"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsNzOB8g4dVV"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec , kelimeleri vektör uzayında ifade etmeye çalışan unsupervised (no labels) ve tahmin temelli(prediction-based) bir modeldir . Google araştırmacı Tomas Mikolov ve ekibi tarafından 2013 yılında icat edilmiştir. 2 çeşit alt algoritmasi vardır: \n",
        "* `CBOW(Continous Bag of Words)`: Pencere boyutu merkezinde OLMAYAN kelimeler girdi olarak alınıp, merkezinde OLAN kelimeler çıktı olarak tahmin edilmeye çalışılmaktadır.\n",
        "* `Skip-Gram`: Pencere boyutu merkezinde OLAN kelimeler girdi olarak alınıp, merkezinde OLMAYAN kelimeler çıktı olarak tahmin edilmeye çalışılmaktadır\n",
        "\n",
        "2 yöntem de genel olarak birbirine benzemektedir."
      ],
      "metadata": {
        "id": "ZuUpxG4g_GCt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CIl3E7bN4dVX"
      },
      "outputs": [],
      "source": [
        "# !pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VL-yxFco4dVa"
      },
      "outputs": [],
      "source": [
        "# pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GKbJKtrz4dVb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4puEaHfd4dVd"
      },
      "outputs": [],
      "source": [
        "text = open(\"/content/drive/MyDrive/Colab Notebooks/NLP/hurriyet.txt\", \"r\", encoding=\"utf8\")\n",
        "text = text.read()\n",
        "list_sent = text.split(\"\\n\")\n",
        "\n",
        "corpus = []\n",
        "\n",
        "for sent in list_sent:\n",
        "    corpus.append(sent.split())\n",
        "# Corpus taki cümleleri split ile ayırarak liste halinde corpus listesine ekliyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixnG75fB4dVf",
        "outputId": "ef4bac9c-9894-4e12-e1de-4cd3e6fc6f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['iran', 'devlet', 'televizyonu', 'ülkedeki', 'eyaletin', 'sinde', 'yapılan', 'reformcuları', 'protesto', 'amaçlı', 'yürüyüşlere', 'milyonlarca', 'kişinin', 'katıldığını', 'bildirdi'], ['gösterilerde', 'fitnecilere', 'ölüm', 'münafıklara', 'ölüm', 'abd', 'ye', 'ölüm', 'ingiltere', 'ye', 'ölüm', 'sloganları', 'atıldı'], ['dini', 'lider', 'ali', 'hamaney', 've', 'cumhurbaşkanı', 'mahmud', 'ahmedinejad', 'ı', 'destekleyen', 'iranlılar', 'son', 'olaylarda', 'yeğeni', 'öldürülen', 'mir', 'hüseyin', 'musevi', 'başta', 'olmak', 'üzere', 'muhalefet', 'liderlerini', 'kınadılar'], ['musevi', 'ye', 'ölüm', 've', 'idam', 'idam', 'sloganları', 'duyuldu'], ['muhalefet', 'liderleri', 'kaçtı', 'mı', 'aşure', 'günü', 'yaşanan', 'çatışmalarda', 'devlet', 'kaynaklarına', 'göre', 'u', 'terörist', 'olmak', 'üzere', 'kişi', 'ölmüştü']]\n"
          ]
        }
      ],
      "source": [
        "print(corpus[:5])\n",
        "# İlk beş cümleye bakıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8FrTiWpo4dVh"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(corpus, size = 100, window =5, min_count=5, sg=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `size = 100` ile 100 lük vectorler oluşturuyoruz.\n",
        "* `windows = 5`; Genellikle bu deger 5 veya 10 verilir. kelimeyi o kelimenin sağında ve solundaki beş kelime kalıbı ile öğren demektir. Örnek: 'iran', 'devlet', 'televizyonu', 'ülkedeki', 'eyaletin','sinde' burada İran kelimesini ele alırsak sağındaki beş kelime ile kullanımını değerlendiriyor, bu değerlendirmeyi bütün corpus taki (Iran birçok cümlede geçiyor) kullanımlarına bakarak bu kelimere olasılık değeri atıyor. \n",
        "* `min_count=5`;  kelime corpus ta 5 den az kullanılmıs ise onu öğrenme demek.\n",
        "* `sg=1`; Egitim sg=1 ise Skip-Gram ile sg=0 ise CBOW ile yapilir. Skip-Gram da hedef kelimeyi çıkararak sağında ve solundaki birer kelime ile bulmaya çalışıyor. (ben .... geldim (hedef ... = eve)). Bu modele kelimenin farklı anlamlarını öğrenmesini sağlır. CBOW ise hedef kelimeye bakarin etrafindaki kelimeleri bulmaya calisir.\n",
        "* Skip-Gram kucuk corpusta daha iyi sonuc verirken CBOW buyuk corpusta daha basarilidir ve CBOW daha hizlidir. Word2Vec default olarak CBOW ile calisir.\n",
        "* Word2Vec kelime kalıplarını (isim tamlaması, sıfat tamlaması, deyim vb.) öğrenirken yukarıdaki parametreleri kullanarak hedef bir kelimenin, o kelimeden sonra veya önce gelen kelimelerle kullanılma olasılıklarına göre öğreniyor ve tahminlemeyi ona göre yapıyor. Yani model ifade kaliplarini ogreniyor diyebiliriz."
      ],
      "metadata": {
        "id": "LtIKuor7C635"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOyhg7E84dVj",
        "outputId": "0d5e9a23-690b-4a87-815e-d653a708d402"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('yapmadım', 0.8479558229446411),\n",
              " ('muydu', 0.8471517562866211),\n",
              " ('sorunum', 0.8257701396942139),\n",
              " ('şeyim', 0.8233948945999146),\n",
              " ('şey', 0.8207236528396606),\n",
              " ('bilgimiz', 0.8166077136993408),\n",
              " ('şeyimiz', 0.8137177228927612),\n",
              " ('bulamıyorum', 0.8134565949440002),\n",
              " ('söylemem', 0.8127145767211914),\n",
              " ('bilemeyiz', 0.8118265867233276)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.wv.most_similar(\"birşey\")\n",
        "# benzer veya birlikte kullanılan kelimeleri kontrol ediyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzutyyuw4dVl",
        "outputId": "6a0a999e-7138-4651-dd0f-f1e464d232dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('marmara', 0.9098492860794067),\n",
              " ('gemisine', 0.673933207988739),\n",
              " ('baskınıyla', 0.6700518727302551),\n",
              " ('baskınına', 0.6264550089836121),\n",
              " ('baskınının', 0.6174196004867554),\n",
              " ('filo', 0.6102496385574341),\n",
              " ('dökme', 0.6097280383110046),\n",
              " ('filosundaki', 0.6068665981292725),\n",
              " ('saldırısındaki', 0.6019788980484009),\n",
              " ('gemisinde', 0.5955616235733032)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.wv.most_similar(\"mavi\")\n",
        "# benzer veya birlikte kullanılan kelimeleri kontrol ediyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP4lc2BK4dVm",
        "outputId": "1bce9a7d-c57e-43fe-acab-f0192dc4e37a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('evine', 0.7970042824745178),\n",
              " ('dükkana', 0.7814911603927612),\n",
              " ('apartmana', 0.7413780689239502),\n",
              " ('mağazaya', 0.7391339540481567),\n",
              " ('arabaya', 0.7272980213165283),\n",
              " ('hapishaneye', 0.7247744798660278),\n",
              " ('karakola', 0.7199428081512451),\n",
              " ('restorana', 0.7095445394515991),\n",
              " ('köye', 0.7060346603393555),\n",
              " ('odasına', 0.7059428691864014)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.wv.most_similar(\"eve\")\n",
        "# benzer veya birlikte kullanılan kelimeleri kontrol ediyoruz."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"hasta\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlPZFVCwNTQ7",
        "outputId": "b7fd5906-a3b6-4c39-b455-253c711f1e49"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('doktor', 0.7463235855102539),\n",
              " ('muayene', 0.7348223924636841),\n",
              " ('hastası', 0.721318244934082),\n",
              " ('kapan', 0.7186871767044067),\n",
              " ('enfeksiyonu', 0.7173671722412109),\n",
              " ('ameliyat', 0.7118446826934814),\n",
              " ('zatürre', 0.7113429307937622),\n",
              " ('doğuma', 0.7101951241493225),\n",
              " ('tedavisini', 0.7093543410301208),\n",
              " ('doktorları', 0.7079592943191528)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxVPkScV4dVn",
        "outputId": "926f6588-d65c-4e24-d087-01944c9e1718"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tedavi', 0.6017300486564636)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model.wv.most_similar(positive=['öğrenci', 'hasta'], negative=['öğretmen'], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sreeVC7Y4dVo",
        "outputId": "dbf21f2e-d31c-4ed4-916a-cfb07a0a6f84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('washington', 0.7370122075080872)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model.wv.most_similar(positive=['moskova', 'ankara'], negative=['rusya'], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['öğretmen', 'doktor'], negative=['öğrenci'], topn=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYiAHCL0Nxei",
        "outputId": "92f3b136-83ce-4422-c0ae-795297331e04"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('hastası', 0.6483066082000732)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p1RgZTa4dVp"
      },
      "source": [
        "## Glove"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Standfor Uni.nin 2014 te gelistirdigi bir model. 400k kelime 6B token ile editilmistir.\n",
        "* Yanyana kullanilan butun kelimeleri once sayiyor, Mesela 'Deep'-'Learning' yanyana kac defa kullanilmis bunun gibi bilgileri toplayip istatistiki bilgi olusturup onunla kelime vektorlerini olusturuyor. \n",
        "* Word2vec e gore daha hizlidir.\n",
        "* Download glove.6B.zip\n",
        "http://nlp.stanford.edu/data/glove.6B.zip\n"
      ],
      "metadata": {
        "id": "4dlO-iqtMMKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "# glove2word2vec un Word2Vec ten farkı vektör olasılıklarını sürekli güncelliyor."
      ],
      "metadata": {
        "id": "XA9V3EmSYxQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kGj0JCH4dVq",
        "outputId": "5708c083-896a-422e-d50b-e5e3290f8b74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "glove_model = \"/content/drive/MyDrive/Glove/glove.6B.100d.txt\"\n",
        "word2vec = \"glove.6B.100d.word2vec\"\n",
        "glove2word2vec(glove_model, word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "-1QBbGPt4dVr"
      },
      "outputs": [],
      "source": [
        "model2 = KeyedVectors.load_word2vec_format(word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw3m6t1g4dVs",
        "outputId": "3010ddfe-7c3b-42ef-ecad-ab7549f68663"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('red', 0.8435065746307373),\n",
              " ('black', 0.8065882921218872),\n",
              " ('pink', 0.786806046962738),\n",
              " ('green', 0.7868044376373291),\n",
              " ('purple', 0.7847141623497009),\n",
              " ('yellow', 0.7777267694473267),\n",
              " ('gray', 0.7732225060462952),\n",
              " ('bright', 0.7431131601333618),\n",
              " ('white', 0.7365070581436157),\n",
              " ('dark', 0.7170193195343018)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "model2.most_similar(\"blue\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2sieeLT4dVs",
        "outputId": "6b97334a-de60-41af-c48b-0bc4d38ef3cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('physician', 0.7673239707946777),\n",
              " ('nurse', 0.75215083360672),\n",
              " ('dr.', 0.7175193428993225),\n",
              " ('doctors', 0.7080885171890259),\n",
              " ('patient', 0.7074184417724609),\n",
              " ('medical', 0.6995993256568909),\n",
              " ('surgeon', 0.6905338764190674),\n",
              " ('hospital', 0.690092921257019),\n",
              " ('psychiatrist', 0.658909797668457),\n",
              " ('dentist', 0.6447421312332153)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model2.most_similar(\"doctor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItH1QeQ34dVt",
        "outputId": "aa4a8bba-f01f-4235-f75b-43ce8e18570e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mother', 0.9024620056152344)]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "model2.most_similar(positive=[\"woman\", \"father\"], negative=[\"man\"], topn=1)\n",
        "# \"father\" \"man\" ise \"woman\" \"mother\" olur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfK3p5Zk4dVu",
        "outputId": "c3fa367e-9d5f-44e0-879b-466a40ad56ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('daughter', 0.8917792439460754)]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "model2.most_similar(positive=[\"woman\", \"brother\"], negative=[\"man\"], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS9aCmqW4dVu",
        "outputId": "134aa750-49e6-43a3-8c00-7717964994bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('turkey', 0.8147119283676147)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "model2.most_similar(positive=[\"ankara\", \"germany\"], negative=[\"berlin\"], topn=1)\n",
        "# germany den berlin i çıkrırsak, ankara yurkey verir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUE5zSrW4dVv",
        "outputId": "c1eba725-1e5d-4d59-9513-477734e0784a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('teacher', 0.7610154151916504)]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "model2.most_similar(positive=[\"teach\", \"doctor\"], negative=[\"treat\"], topn=1)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "43a9cd95aa030499ef934e4da31e07dde54f3fc3a1fd0cc4aeef7f16459ee2ac"
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit (system)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "name": "Word Embedding (word2vec, Glove).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}